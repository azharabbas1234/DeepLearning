{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2337fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\" Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\n",
    "Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19baa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e409f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in data.split('\\n'):\n",
    "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "  for i in range(1,len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1])\n",
    "    print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f939996",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246863ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= padded_input_sequences[:,:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd912f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e6d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
